# -*- coding: utf-8 -*-
"""ECE 9603 Priya A1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1szWT8GBb6kr-g-Xxl6AvSeODk5Hc6E0y
"""

from google.colab import drive
drive.mount('/content/drive')

# import libraries
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns



df=pd.read_csv("/content/drive/MyDrive/ECE9603/breast_cancer.csv")

df.head()

df.shape

df.isnull().sum()

df.info()

df.dropna(axis=1,inplace=True)

df.info()

"""The dataset contains patients 212 with cancer and 357  with no cancer.

1. As we have so many features, so using pair plot
2. Get the correlation between the features
"""

df['diagnosis'].value_counts()

corr = df.corr()
plt.figure(figsize=(20,20))
sns.heatmap(corr, cmap='inferno')
plt.show()

"""**Encoding Categorical data values**"""

sns.countplot(df['diagnosis'],label='Cancer_count')

from sklearn.preprocessing import LabelEncoder
labelenco_y=LabelEncoder()
df.loc[:,'diagnosis']=labelenco_y.fit_transform(df.loc[:,'diagnosis'].values)   #input array to dataframe

"""**Pair plot with respect to all the correlated features**



"""

df.head()

"""In heat map correlation we can se that 
1. concave_points_worst, 
2. area_worst,
3. perimeter_worst,
4. radius_worst,
5. concave points_mean, 
6. perimeter mean,
7. radius mean 

**these all are most 7 co-related with the diagnosis which is greater than 70%**
"""

df.corr()

#plt.figure(figsize=(25,25))
#sns.heatmap(df.corr(),annot=True)

sns.pairplot(df, hue = 'diagnosis', 
            vars = ['radius_mean', 'concave points_worst', 'perimeter_mean', 'area_worst', 'perimeter_worst','radius_worst','concave points_mean'] )

"""** Scaling the data so that different magnitude and range of data can get into 1 range **

**Split the dataset in to X and Y**

This plot is showing the factors by which we can predit to detect the cancer

**Split Dataset in to 75% training and 25% testing **
"""

X=df.iloc[:,2:]
Y=df.iloc[:,1]

from sklearn.model_selection import train_test_split 
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=1,shuffle = True, stratify = Y)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)

X_test_sc

"""**Training, crossvalidation, evaluation all the 3 models**"""

from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

def models(X_train,Y_train):
  #Logistic Regression
  print()
  print('Logistic Regression')
  print()
  from sklearn.linear_model import LogisticRegression
  log=LogisticRegression(random_state=51)
  log.fit(X_train,Y_train)
  y_pred_log=log.predict(X_test_sc)
  cm=confusion_matrix(Y_test,y_pred_log)
  plt.title('Heatmap of Confusion Matrix', fontsize = 15)
  sns.heatmap(cm, annot = True)
  plt.show()
  print(cm)
  print(classification_report(Y_test,y_pred_log))
  print(accuracy_score(Y_test,y_pred_log))
  print()
  print('All K- fold cross val',cross_val_score(log, X_train_sc, Y_train, cv=5))
  print('Mean of all K-fold cross Val',np.mean(cross_val_score(log, X_train_sc, Y_train, cv=5)))

  #Decision Tree
  print()
  print('Decision Tree')
  print()
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)
  tree.fit(X_train, Y_train)
  y_pred_tree=tree.predict(X_test_sc)
  cm=confusion_matrix(Y_test,y_pred_tree)
  plt.title('Heatmap of Confusion Matrix', fontsize = 15)
  sns.heatmap(cm, annot = True)
  plt.show()
  print(cm)
  print(classification_report(Y_test,y_pred_tree))
  print(accuracy_score(Y_test,y_pred_tree))
  print()
  print('All K- fold cross val',cross_val_score(tree, X_train_sc, Y_train, cv=5))
  print('Mean of all K-fold cross Val',np.mean(cross_val_score(tree, X_train_sc, Y_train, cv=5)))


  # K – Nearest Neighbor Classifier
  print()
  print('K – Nearest Neighbor Classifier(KNN)')
  print()
  from sklearn.neighbors import KNeighborsClassifier
  knn= KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
  knn.fit(X_train, Y_train)
  y_pred_knn=knn.predict(X_test_sc)
  cm=confusion_matrix(Y_test,y_pred_knn)
  plt.title('Heatmap of Confusion Matrix', fontsize = 15)
  sns.heatmap(cm, annot = True)
  plt.show()
  print(cm)
  print(classification_report(Y_test,y_pred_knn))
  print(accuracy_score(Y_test,y_pred_knn))
  print()
  print('All K- fold cross val',cross_val_score(knn, X_train_sc, Y_train, cv=5))
  print('Mean of all K-fold cross Val',np.mean(cross_val_score(knn, X_train_sc, Y_train, cv=5)))

  print()
  

  return log,tree,knn

model=models(X_train_sc,Y_train)

